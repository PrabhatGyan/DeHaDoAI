{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee2cce20",
   "metadata": {},
   "source": [
    "# DeHaDO-AI || NCVPTIPG-2025\n",
    "[Challenge Website](https://sites.google.com/view/dehado-ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea567f0",
   "metadata": {},
   "source": [
    "## Load all the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4503ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from decord import VideoReader, cpu\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e3eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt import load_prompt\n",
    "from internvl import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632b016",
   "metadata": {},
   "source": [
    "## Define all the relevenat paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd8dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/DATA/gyan/GP/ncvpripg2025/dehado/'\n",
    "\n",
    "PATH_PHASE_1 = os.path.join(BASE_PATH,'DEHADO-AI_TRAINING_DATASET')\n",
    "PATH_PHASE_2 = os.path.join(BASE_PATH,'DEHADO-AI_TRAINING_DATASET_PHASE_II')\n",
    "PATH_PHASE_TEST = os.path.join(BASE_PATH,'IMAGES')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4805cf",
   "metadata": {},
   "source": [
    "### Select the Image folder, we want to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586038da",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_IMAGE_FOLDER = PATH_PHASE_TEST # CHNAGE THE SELECTION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SELECTED_IMAGE_FOLDER == PATH_PHASE_1:\n",
    "    output_path = '/DATA/gyan/GP/ncvpripg2025/dehado/output_phase_3_01'\n",
    "elif SELECTED_IMAGE_FOLDER == PATH_PHASE_2:\n",
    "    output_path = '/DATA/gyan/GP/ncvpripg2025/dehado/output_phase_3_02'\n",
    "elif SELECTED_IMAGE_FOLDER == PATH_PHASE_TEST:\n",
    "    output_path = '/DATA/gyan/GP/ncvpripg2025/dehado/output_phase_test'\n",
    "else:\n",
    "    raise Exception('Wrong choice of Image Folder!')\n",
    "\n",
    "\n",
    "print(f'The Output Path is: {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86ec9a4",
   "metadata": {},
   "source": [
    "### Choose the Image Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd43b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SELECTED_IMAGE_FOLDER == PATH_PHASE_1) or (SELECTED_IMAGE_FOLDER == PATH_PHASE_2):\n",
    "    IMG_PATH = os.path.join(SELECTED_IMAGE_FOLDER,'IMAGES_750')\n",
    "elif (SELECTED_IMAGE_FOLDER == PATH_PHASE_TEST):\n",
    "    IMG_PATH = SELECTED_IMAGE_FOLDER\n",
    "else:\n",
    "    raise Exception('Error! Wrong folder is selected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe9b2d",
   "metadata": {},
   "source": [
    "### Get all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db123bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = os.listdir(IMG_PATH)\n",
    "print(f'There are {len(all_images)} images present.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6963441",
   "metadata": {},
   "source": [
    "## Load the Prompt File for the InternVL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f5896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = load_prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f615dd15",
   "metadata": {},
   "source": [
    "### Build the question for the InternVL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6774ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = '<image>\\n' + prompt\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46a951b",
   "metadata": {},
   "source": [
    "## Load the InternVL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e75a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'OpenGVLab/InternVL3-8B'\n",
    "model = AutoModel.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_flash_attn=True,\n",
    "    trust_remote_code=True).eval().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True, use_fast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9619d709",
   "metadata": {},
   "source": [
    "## Which images have already been passed to OCR and we have results\n",
    "1. We are saving each output as a seperate json file. \n",
    "2. We always check for all the images which we have already processed.\n",
    "3. This way, we have to run for only those images which are left, even if the for loop breaks due to any issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8519c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_done = os.listdir(output_path)\n",
    "print(f'OCR is already done for : {len(ocr_done)} images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6262b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_remaining_images(all_images, ocr_done):\n",
    "    \n",
    "    # Clean the ocr_done list (remove .txt extension)\n",
    "    ocr_done_cleaned = {os.path.splitext(name)[0] for name in ocr_done}\n",
    "    \n",
    "    # Filter all_images: keep original name if base name not in ocr_done_cleaned\n",
    "    left_images = [img for img in all_images if os.path.splitext(img)[0] not in ocr_done_cleaned]\n",
    "    \n",
    "    return left_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122d9a6",
   "metadata": {},
   "source": [
    "### List down all the images which are left to be passed into InternVL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4259fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_images = get_remaining_images (all_images = all_images,\n",
    "                                    ocr_done = ocr_done)\n",
    "print(f'We have a total of {len(left_images)} images which are left to be OCRed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_files = list()\n",
    "\n",
    "for sel_image in left_images:\n",
    "\n",
    "    try:\n",
    "        sel_img_path = os.path.join(IMG_PATH,sel_image)\n",
    "\n",
    "        # set the max number of tiles in `max_num`\n",
    "        pixel_values = load_image(sel_img_path, \n",
    "                                max_num=12).to(torch.bfloat16).cuda()\n",
    "        \n",
    "        # Create the Config - max_new_tokens can be changed\n",
    "        # Add the eos and pad token to resolve the warnings\n",
    "        generation_config = dict(max_new_tokens=1024,\n",
    "                                 do_sample=True, \n",
    "                                 eos_token_id=151645, \n",
    "                                 pad_token_id=151645)\n",
    "\n",
    "        # Generate the response from InternVL\n",
    "        response = model.chat(tokenizer, pixel_values, question, generation_config)\n",
    "\n",
    "        # Save the output a .txt file\n",
    "        nm,_ = os.path.splitext(sel_image)\n",
    "        txt_filename = nm + '.txt'\n",
    "        txt_path = os.path.join(output_path,txt_filename)\n",
    "\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response)\n",
    "    except:\n",
    "        error_files.append(sel_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f8a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'we have {len(error_files)} errored files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e281b6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncvpripg_internvl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
